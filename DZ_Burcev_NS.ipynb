{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RuSxPbblHJK1"
   },
   "outputs": [],
   "source": [
    "# Домашнее задание\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJlrSHw9Fz1x"
   },
   "outputs": [],
   "source": [
    "# задача 1\n",
    "\n",
    "# Найти корни квадратного уравнения методом градиентного спуска\n",
    "# x ** 2 - 5 * x + 4 = 0\n",
    "\n",
    "# надо начать движение от начальной точки в направлении антградиента с заданным шагом\n",
    "# x = x - lr * grad(x)\n",
    "# всегда ли сойдемся за приемлемое количество шагов?\n",
    "# важна ли начальная точка?\n",
    "# как найти второй корень?\n",
    "# как влияет ЛР?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найденный корень: 2.499999514836731\n",
      "Найденный второй корень: 2.5000004888968688\n"
     ]
    }
   ],
   "source": [
    "def func(x):\n",
    "    return x ** 2 - 5 * x + 4\n",
    "\n",
    "def grad(x):\n",
    "    return 2 * x - 5\n",
    "\n",
    "def gradient_descent(starting_x, lr, epochs):\n",
    "    x = starting_x\n",
    "    for i in range(epochs):\n",
    "        gradient = grad(x)\n",
    "        x = x - lr * gradient\n",
    "        if abs(gradient) < 1e-6:  # условие остановки, если градиент близок к нулю\n",
    "            break\n",
    "    return x\n",
    "\n",
    "# Параметры\n",
    "starting_x = 0  # начальная точка\n",
    "lr = 0.01       # величина шага\n",
    "epochs = 1000   # количество итераций\n",
    "\n",
    "root1 = gradient_descent(starting_x, lr, epochs)\n",
    "print(f\"Найденный корень: {root1}\")\n",
    "\n",
    "# Для нахождения второго корня, можно изменить начальную точку\n",
    "starting_x2 = 10  # другая начальная точка\n",
    "root2 = gradient_descent(starting_x2, lr, epochs)\n",
    "print(f\"Найденный второй корень: {root2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задача 2\n",
    "\n",
    "# Реализовать адаптивний оптимизатор с подстраивающимся LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a2swiHK-HIOq"
   },
   "outputs": [],
   "source": [
    "# Task 2\n",
    "# Realize forward and backward pass for linear layer with sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1667663676928,
     "user": {
      "displayName": "Boris Zhestkov",
      "userId": "15589718157134474454"
     },
     "user_tz": -180
    },
    "id": "ibFFthYnHIlh"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1. / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_backward(da, x):\n",
    "    sig = sigmoid(x)\n",
    "    \n",
    "    return da * sig * (1 - sig)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0., x)\n",
    "\n",
    "def relu_backward(da, x):\n",
    "    da = np.array(da, copy = True)\n",
    "    da[x <= 0] = 0\n",
    "    return da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1667663680426,
     "user": {
      "displayName": "Boris Zhestkov",
      "userId": "15589718157134474454"
     },
     "user_tz": -180
    },
    "id": "gvMKpB5WFz1z"
   },
   "outputs": [],
   "source": [
    "def mse_loss(t, y):\n",
    "    return (t - y) ** 2\n",
    "\n",
    "def d_mse_loss(t, y):\n",
    "    return 2 * (y - t) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1667663684513,
     "user": {
      "displayName": "Boris Zhestkov",
      "userId": "15589718157134474454"
     },
     "user_tz": -180
    },
    "id": "-qAVeaVcFz10"
   },
   "outputs": [],
   "source": [
    "class LinearLayer:\n",
    "    def __init__(self, n_inp, n_out, activation='sigmoid'):\n",
    "        self.w = np.random.randn(n_out, n_inp) * 0.1\n",
    "        self.b = np.random.randn(n_out, 1) * 0.1\n",
    "        if activation == 'sigmoid':\n",
    "            self.activ = sigmoid\n",
    "        if activation == 'relu':\n",
    "            self.activ = relu\n",
    "        elif activation == 'None':\n",
    "            self.activ = None\n",
    "        else:\n",
    "            raise Exception(f'Unknown activation \"{activation}\"')\n",
    "        self._clear_state()\n",
    "\n",
    "    def _clear_state(self):\n",
    "        self.lin = None\n",
    "        self.inp = None\n",
    "        self.d_w = None\n",
    "        self.d_b = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.inp = x\n",
    "        self.lin = np.dot(self.w, x) + self.b\n",
    "        activ = self.activ(self.lin) if self.activ is not None else self.lin\n",
    "        \n",
    "        return activ\n",
    "\n",
    "    def backward(self, grad): # grad = d L / d z    Dout \n",
    "        # grad * dz / d lin\n",
    "        if self.activ == sigmoid:\n",
    "            grad_lin = sigmoid_backward(grad, self.lin)\n",
    "        if self.activ == relu:\n",
    "            grad_lin = relu_backward(grad, self.lin)\n",
    "        else:\n",
    "            grad_lin = grad\n",
    "        # grad_lin * d lin / d w \n",
    "        m = self.inp.shape[1]\n",
    "        self.d_w = grad_lin @ self.inp.T / m\n",
    "        # grad_lin * d lin / d b \n",
    "        self.d_b = np.sum(grad_lin, axis=1, keepdims=True) / m\n",
    "        \n",
    "        grad = np.dot(self.w.T, grad_lin)\n",
    "        \n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1667663288846,
     "user": {
      "displayName": "Boris Zhestkov",
      "userId": "15589718157134474454"
     },
     "user_tz": -180
    },
    "id": "jUZcVU8z2T-t"
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, arch: Tuple[Tuple[int, int]], activation):\n",
    "        self.layers = []\n",
    "        for i, p in enumerate(arch):\n",
    "            self.layers.append(\n",
    "                LinearLayer(p[0], p[1], \n",
    "                            activation=activation if i < len(arch)-1 else 'None')\n",
    "                )\n",
    "        self._clear_state()\n",
    "    \n",
    "    def _clear_state(self):\n",
    "        for l in self.layers:\n",
    "            l._clear_state()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l.forward(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def backward(self, grad):\n",
    "        for l in reversed(self.layers):\n",
    "            grad = l.backward(grad)\n",
    "\n",
    "        return grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KmLRIBk4Fz12"
   },
   "outputs": [],
   "source": [
    "# Task 3\n",
    "# Realize SGD \n",
    "# velocity = SGD * velocity - lr * gradient\n",
    "# w = w + velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[-0.16162085]] [[-0.21652563]] [[-0.060777]] [[-0.03738077]]\n",
      "1 [[1.86022001]] [[2.76312979]] [[2.18840731]] [[3.33059818]]\n",
      "2 [[2.50503733]] [[4.10633088]] [[2.55191573]] [[4.17771888]]\n",
      "3 [[2.43576914]] [[4.32115588]] [[2.42342654]] [[4.29521622]]\n",
      "4 [[2.29616482]] [[4.38141625]] [[2.27300725]] [[4.34876254]]\n",
      "5 [[2.16104474]] [[4.41558102]] [[2.13320263]] [[4.3823481]]\n",
      "6 [[2.03733733]] [[4.43945792]] [[2.00541798]] [[4.4036934]]\n",
      "7 [[1.92558706]] [[4.45607778]] [[1.89111635]] [[4.41969409]]\n",
      "8 [[1.82619793]] [[4.4677268]] [[1.79043316]] [[4.431811]]\n",
      "9 [[1.73869118]] [[4.47618792]] [[1.70222216]] [[4.44072034]]\n",
      "10 [[1.66214826]] [[4.48237257]] [[1.62547847]] [[4.44778599]]\n",
      "11 [[1.59540231]] [[4.48679181]] [[1.55890164]] [[4.45287245]]\n",
      "12 [[1.53732645]] [[4.48989759]] [[1.50128098]] [[4.45656507]]\n",
      "13 [[1.48675231]] [[4.49196248]] [[1.45121616]] [[4.45899567]]\n",
      "14 [[1.44261975]] [[4.49321944]] [[1.40768949]] [[4.46062291]]\n",
      "15 [[1.40389316]] [[4.4938533]] [[1.36953734]] [[4.46150711]]\n",
      "16 [[1.36953129]] [[4.49383384]] [[1.33571806]] [[4.46172023]]\n",
      "17 [[1.33869964]] [[4.49332817]] [[1.30549349]] [[4.46147606]]\n",
      "18 [[1.31074692]] [[4.49249684]] [[1.27811023]] [[4.46080255]]\n",
      "19 [[1.28505639]] [[4.49132924]] [[1.25295509]] [[4.45974613]]\n"
     ]
    }
   ],
   "source": [
    "class SGD:\n",
    "    def __init__(self, model, lr=0.0001):\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self):\n",
    "        for layer in self.model.layers:\n",
    "            layer.w -= self.lr * layer.d_w\n",
    "            layer.b -= self.lr * layer.d_b\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.model._clear_state()\n",
    "\n",
    "# Пример использования оптимизатора SGD\n",
    "model = Model(((1, 100), (100, 1)), activation='relu')\n",
    "optim = SGD(model, lr=0.00001)\n",
    "for e in range(20):\n",
    "    print(e, model.forward([[1]]), model.forward([[2]]), model.forward([[-1]]), model.forward([[-2]]))\n",
    "    for i, (val, t) in enumerate(zip(x, y)):\n",
    "        optim.zero_grad()\n",
    "        pred = model.forward(np.array([[val]]))\n",
    "        loss = mse_loss(t, pred)\n",
    "        grad = d_mse_loss(t, pred)\n",
    "        model.backward(grad)\n",
    "        optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_5jAO8pVFz19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 [[1.26110143]] [[4.48985439]] [[1.22942235]] [[326.19511883]]\n"
     ]
    }
   ],
   "source": [
    "print(e, model.forward([[1]]), model.forward([[2]]), model.forward([[-1]]), model.forward([[103]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOOY8douFz1-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zROVnJAcFz1-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QWQyu5NFz1-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
